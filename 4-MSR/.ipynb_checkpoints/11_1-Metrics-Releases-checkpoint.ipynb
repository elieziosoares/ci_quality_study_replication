{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populates Table Metrics Period\n",
    "\n",
    "Metrics Period:\n",
    "* 1 record per month/week\n",
    "* Get analysis_init month and year\n",
    "* Fill 12 consecutive months\n",
    "\n",
    "## Summarize metrics by period\n",
    "\n",
    "* Commit Size\n",
    "* Test Volume\n",
    "* Merge Conflicts\n",
    "* Communication\n",
    "* Bugs\n",
    "* Bugs Ratio\n",
    "* Age\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the table Metric Release:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:37:43.729208Z",
     "start_time": "2022-07-09T00:37:09.125342Z"
    }
   },
   "outputs": [],
   "source": [
    "repos = getProjectsReleases()\n",
    "#select P.repo_name,P.analysis_init,P.analysis_finish,R.NODE_ID,R.created_at,P.ci,P.created\n",
    "\n",
    "for repo in repos:    \n",
    "    project = repo[0]\n",
    "    analysisInit = repo[1]  \n",
    "    analysisFinish = repo[2]  \n",
    "    release = repo[3]  \n",
    "    release_creation = repo[4]  \n",
    "    ci = repo[5]  \n",
    "    repo_creation = repo[6]\n",
    "    \n",
    "    saveReleaseMetrics(project,ci,release,release_creation,repo_creation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the table Metric Release with metrics\n",
    "* Commit Size, Test Volume, Merge Conflicts, Communication, Bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveReleaseMetrics(project,ci,release,release_creation,repo_creation):\n",
    "    print('Project: {}\\t\\t Release: {}'.format(project,release))\n",
    "    \n",
    "    prs = getPrs(project,release)\n",
    "    if len(prs) == 0:\n",
    "        print('\\t\\t\\t saiu no len(prs)')\n",
    "        return\n",
    "    \n",
    "    bugs = getBugs(project,release)\n",
    "    bugs = int(bugs['bugs'][0])\n",
    "    issues = getIssues(project,release)\n",
    "    issues = int(issues['issues'][0])\n",
    "    \n",
    "    if issues == 0:\n",
    "        bugs_ratio = 0\n",
    "    else:\n",
    "        bugs_ratio = bugs/issues\n",
    "        \n",
    "    print(f'\\t\\t issues: {issues} - bugs: {bugs} - bugs_ratio: {bugs_ratio}')\n",
    "    \n",
    "    age = abs(release_creation - repo_creation).days\n",
    "    communication = getCommunication(project,release)\n",
    "    conflicts = getMergeConflicts(project,release)\n",
    "    conflictsGit = getMergeConflictsGit(project,release)\n",
    "    frequency_authors = getFrequencyAuthors(project,release)\n",
    "    \n",
    "    builds = getBuilds(project, release)\n",
    "    commits = sum(map(lambda x: int(x), prs['commits'].tolist())) \n",
    "    \n",
    "    #test_proportion ou test_volume\n",
    "    try:\n",
    "        test_vol = prs['test_volume'].sum()\n",
    "        commit_size = prs['commit_size'].sum()\n",
    "        if test_vol == 0:\n",
    "            test_vol_proportional = 0\n",
    "        else:\n",
    "            test_vol_proportional = (test_vol/commit_size)\n",
    "    except Exception as e:\n",
    "        test_vol_proportional = 0\n",
    "        \n",
    "    #print(f'\\t\\t test_vol_prop: {test_vol_proportional} - test_vol: {test_vol} - commit_size: {commit_size}')\n",
    "    #print('\\t\\t Communication mean: {} - communication median: {} - merge conflicts: {}'.format(communication['communication'].mean(),communication['communication'].median(),conflicts['conflicts'][0]))\n",
    "    #print(f'\\t\\t bugs: {bugs} - builds: {len(builds)} - commits: {commits}')\n",
    "    #print(f'\\t\\t age: {age} - bugs_ratio: {bugs_ratio}\\n')   \n",
    "                        #repo_name,release,ci,qtdPR, commit_size_mean,         commit_size_median,         commit_size_perfile_mean,            commit_size_perfile_median,           test_volume_mean,                                 test_volume_median,                         communication_mean,                   communication_median,                                                                                                                                       merge_conflicts,      bugs,  qtybuilds, commits,test_vol_proportional,age,bugs_ratio):   \n",
    "    insertMetricsRelease(project,release,release_creation,ci,len(prs),prs['commit_size'].mean(),prs['commit_size'].median(),prs['commit_size_per_file'].mean(),prs['commit_size_per_file'].median(),(prs['test_volume']/prs['commit_size']).mean(),(prs['test_volume']/prs['commit_size']).median(),communication['communication'].mean(),communication['communication'].median(),frequency_authors['author_frequency'].mean(),frequency_authors['author_frequency'].median(),int(conflicts['conflicts'][0]),int(conflictsGit['conflicts'][0]),bugs, len(builds),commits,test_vol_proportional,age,bugs_ratio)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aux Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.502836Z",
     "start_time": "2022-07-09T00:35:53.917004Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "import requests \n",
    "import time\n",
    "import pytz    \n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.507540Z",
     "start_time": "2022-07-09T00:35:55.504364Z"
    }
   },
   "outputs": [],
   "source": [
    "def connectDB():\n",
    "    f = open('/home/psql_pwd.txt', \"r\")\n",
    "    pwd = f.readline().replace('\\n','')\n",
    "    \n",
    "    return psycopg2.connect(user = \"ci_quality\",\n",
    "                              password = pwd,\n",
    "                              host = \"127.0.0.1\",\n",
    "                              port = \"5432\",\n",
    "                              database = \"Causal_CI_Quality_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectDBPandas():\n",
    "    f = open('/home/psql_pwd.txt', \"r\")\n",
    "    pwd = f.readline().replace('\\n','')\n",
    "    DATABASE_URI = 'postgresql://ci_quality:{}@localhost:5432/Causal_CI_Quality_v4'.format(pwd)\n",
    "    \n",
    "    return create_engine(DATABASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.578902Z",
     "start_time": "2022-07-09T00:35:55.558012Z"
    }
   },
   "outputs": [],
   "source": [
    "def getProjectsReleases():    \n",
    "    query = \"\"\"select P.repo_name,P.analysis_init,P.analysis_finish,R.NODE_ID,R.created_at,P.ci,P.created\n",
    "                from projects P INNER JOIN project_releases R ON P.repo_name = R.repo_name\n",
    "                WHERE P.RQ1_INCLUDED IS TRUE and R.created_at BETWEEN P.analysis_init AND P.analysis_finish\n",
    "\n",
    "                and P.repo_name NOT IN (select distinct repo_name from metrics_releases)\n",
    "                \n",
    "                ORDER BY P.repo_name,R.CREATED_AT asc;\"\"\"\n",
    "    \n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.648597Z",
     "start_time": "2022-07-09T00:35:55.606120Z"
    }
   },
   "outputs": [],
   "source": [
    "def getProjectPeriods():\n",
    "    query = \"\"\"select repo_name, init_period, end_period from METRICS_PERIOD\n",
    "    WHERE PERIOD iLIKE 'MONTH' \n",
    "    --and before_ci is true\n",
    "    --and repo_name IN ( select repo_name from projects where rq1 is true)\n",
    "    order by repo_name,period,init_period\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.674898Z",
     "start_time": "2022-07-09T00:35:55.650475Z"
    }
   },
   "outputs": [],
   "source": [
    "def insertPeriod(project,init_period,end_period,order,metric,beforeCI,ci):\n",
    "    connection = connectDB()\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO metrics_period (repo_name,init_period,end_period,order_period,period,before_ci,ci) \n",
    "        VALUES(\"\"\"+'%s,'*6+'%s);'\n",
    "\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query,[project,init_period,end_period,order,metric,beforeCI,ci])\n",
    "\n",
    "        connection.commit()\n",
    "        #print('INSERT INTO metrics_period (repo_name,init_period,end_period,order_period,period) VALUES({},{},{},{},{})'.format(project,init_period,end_period,order,metric))\n",
    "    except Exception as e:\n",
    "        print (\"Error while inserting into PostgreSQL. insertPeriod >>> Repository: {}, init: {}, finish: {}\".format(repo, init_period,end_period)) \n",
    "        print(e)\n",
    "    finally:\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.700385Z",
     "start_time": "2022-07-09T00:35:55.678876Z"
    }
   },
   "outputs": [],
   "source": [
    "def getPrs(project_name,release):\n",
    "    connection = connectDBPandas()\n",
    "    query = \"\"\"select commit_size,(commit_size/files) commit_size_per_file,(test_volume/commit_size) TEST_PROPORTION,test_volume,commits \n",
    "                from pullrequests \n",
    "                WHERE release_id like %s AND project_name ilike %s AND commit_size is not null AND commit_size >0;\"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query,con=connection,params=[release,project_name])\n",
    "    connection.dispose()\n",
    "    return df\n",
    "    #Check if column contains all values 0. In this case we do not filter outliers.\n",
    "    #if checkValues(df['commit_size']) and checkValues(df['test_volume']):\n",
    "    #    return df\n",
    "    #else:\n",
    "    #    return removeOutliers(df)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.751849Z",
     "start_time": "2022-07-09T00:35:55.702625Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCommunication(project_name,release):\n",
    "    connection = connectDBPandas()\n",
    "    query = \"\"\"select (\"Comments\"+review_comments) COMMUNICATION \n",
    "                from pullrequests WHERE release_id like %s AND project_name ilike %s AND (\"Comments\" is not null or review_comments is not null);\"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query,con=connection,params=[release,project_name])\n",
    "    connection.dispose()\n",
    "    return df\n",
    "    #Check if column contains all values 0. In this case we do not filter outliers.\n",
    "    #if checkValues(df['communication']):\n",
    "    #    return df\n",
    "    #else:\n",
    "    #    return removeOutliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrequencyAuthors(project_name,release):\n",
    "    connection = connectDBPandas()\n",
    "    query = \"\"\"select author_frequency\n",
    "                from pullrequests WHERE release_id like %s AND project_name ilike %s;\"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query,con=connection,params=[release,project_name])\n",
    "    connection.dispose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.775693Z",
     "start_time": "2022-07-09T00:35:55.756593Z"
    }
   },
   "outputs": [],
   "source": [
    "def getMergeConflicts(project_name,release):\n",
    "    connection = connectDBPandas()\n",
    "    query = \"\"\"select count(id) conflicts from PULLREQUESTS \n",
    "    where project_name ilike %s AND release_id like %s AND mergeconflict is True\"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query,con=connection,params=[project_name,release])\n",
    "    connection.dispose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMergeConflictsGit(project_name,release):\n",
    "    connection = connectDBPandas()\n",
    "    query = \"\"\"select count(repo_name) conflicts from MERGE_CONFLICT \n",
    "    where repo_name ilike %s AND release_id like %s;\"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query,con=connection,params=[project_name,release])\n",
    "    connection.dispose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.800816Z",
     "start_time": "2022-07-09T00:35:55.778151Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBugs(project_name,release):\n",
    "    query = \"\"\"select count(id) bugs from ISSUE \n",
    "    where repo_name like %s AND release_id like %s AND ISBUG IS TRUE;\"\"\"\n",
    "\n",
    "    connection = connectDBPandas()\n",
    "    df = pd.read_sql_query(query,con=connection,params=[project_name,release])\n",
    "    connection.dispose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.829292Z",
     "start_time": "2022-07-09T00:35:55.802390Z"
    }
   },
   "outputs": [],
   "source": [
    "def getIssues(project_name,release):\n",
    "    query = \"\"\"select count(id) issues from ISSUE \n",
    "    where repo_name like %s AND release_id like %s;\"\"\"\n",
    "\n",
    "    connection = connectDBPandas()\n",
    "    df = pd.read_sql_query(query,con=connection,params=[project_name,release])\n",
    "    connection.dispose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.876037Z",
     "start_time": "2022-07-09T00:35:55.834866Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://www.kite.com/python/answers/how-to-remove-outliers-from-a-pandas-dataframe-in-python\n",
    "def removeOutliers(df):\n",
    "    z_scores = stats.zscore(df)\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "    df_filtered = df[filtered_entries]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:55.901339Z",
     "start_time": "2022-07-09T00:35:55.878104Z"
    }
   },
   "outputs": [],
   "source": [
    "def checkValues(df):\n",
    "    if (df == 0).all():\n",
    "        return True\n",
    "    else:\n",
    "        i=v=0\n",
    "        v = df[0]\n",
    "        for a in df:\n",
    "            if a != v:\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T02:57:57.398664Z",
     "start_time": "2022-07-09T02:57:57.375873Z"
    }
   },
   "outputs": [],
   "source": [
    "def insertMetricsRelease(repo_name,release,release_creation,ci,qtdPR,commit_size_mean,commit_size_median,commit_size_perfile_mean,commit_size_perfile_median,test_volume_mean,test_volume_median,communication_mean,communication_median,author_frequency_mean,author_frequency_median,merge_conflicts,merge_conflictsGit,bugs,qtybuilds,commits,test_vol_proportional,age,bugs_ratio):\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO METRICS_RELEASES(repo_name,release_id,created_at,ci,commit_size_mean,commit_size_median,\n",
    "                    commit_size_perfile_mean,commit_size_perfile_median,test_volume_mean,test_volume_median,\n",
    "                    communication_mean,communication_median,author_frequency_mean,author_frequency_median,merge_conflicts,merge_conflicts_git,bugs,qtd_pull_request,qty_builds,qty_commits,\n",
    "                    test_volume_proportional,age,bugs_ratio)\n",
    "                VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s);\"\"\"\n",
    "\n",
    "        query_print=f\"\"\"INSERT INTO METRICS_RELEASES(repo_name,release_id,created_at,ci,commit_size_mean,commit_size_median,\n",
    "                    commit_size_perfile_mean,commit_size_perfile_median,test_volume_mean,test_volume_median,\n",
    "                    communication_mean,communication_median,author_frequency_mean,author_frequency_median,merge_conflicts,merge_conflicts_git,bugs,qtd_pull_request,qty_builds,qty_commits,\n",
    "                    test_volume_proportional,age,bugs_ratio)\n",
    "                VALUES({repo_name},{release},{release_creation},{ci},{commit_size_mean},{commit_size_median},{commit_size_perfile_mean},{commit_size_perfile_median},{test_volume_mean},{test_volume_median},{communication_mean},{communication_median},{author_frequency_mean},{author_frequency_median},{merge_conflicts},{merge_conflictsGit},{bugs},{qtdPR},{qtybuilds},{commits},{test_vol_proportional},{age},{bugs_ratio});\"\"\"\n",
    "        \n",
    "        #print(query_print)\n",
    "        \n",
    "        connection = connectDB()\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        cursor.execute(query, [repo_name,release,release_creation,ci,commit_size_mean,commit_size_median,commit_size_perfile_mean,commit_size_perfile_median,test_volume_mean,test_volume_median,communication_mean,communication_median,author_frequency_mean,author_frequency_median,merge_conflicts,merge_conflictsGit,bugs,qtdPR,qtybuilds,commits,test_vol_proportional,age,bugs_ratio])\n",
    "        connection.commit()\n",
    "        connection.close()\n",
    "    except psycopg2.IntegrityError as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while updating into PostgreSQL. insertMetricsRelease >>> Exception: {}\".format(e)) \n",
    "        print('Project: {}    Release - {}'.format(repo_name,release))\n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while processing insertMetricsRelease >>> Exception: {}\".format(e)) \n",
    "        print('Project: {}    Release - {}'.format(repo_name,release))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T00:35:56.019770Z",
     "start_time": "2022-07-09T00:35:55.976088Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBuilds(repo_name,release):\n",
    "    #print('****** Computing Build Health. Repo {}'.format(repo_name))\n",
    "    \n",
    "    query = \"\"\"SELECT state FROM builds_mined WHERE \n",
    "            repo_name like %s AND release_id like %s;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name,release])\n",
    "    rows = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
