{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Re-Calculate analysis period\n",
    "\n",
    "##### Motivation:\n",
    "- Among CI projects we found 76 without bugs in the selected period, however  with bugs in other periods.\n",
    "- Several projects adopt CI service, but start doing automated builds and monitoring coverage only some time after. Therefore we can supose that indeed such projects employ CI on that date.\n",
    "\n",
    "##### Procedure:\n",
    "- We now consider the date of first coverage record for projects using Travis CI. This is due our criteria in consider CI projects those having automated builds and coverage metric.\n",
    "- Columns were added to Projects table:\n",
    "  - cov_init\n",
    "  - cov_init_days\n",
    "  - ci_service_init\n",
    "  - ci_service_init_days\n",
    "- Redifine analysis_point_days for projects using CI Service\n",
    "- Get the new median days for CI projects (having cov_init not null) and set it on NO CI projects\n",
    "- Redifine analysis_init and analysis_finish for all projects\n",
    "\n",
    "##### Reminds:\n",
    "- Re-execute merge_conflict process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Setting Cov_init and Cov_init_days\n",
    "\n",
    "- Get first coverage record to set cov_init\n",
    "- Diff between days (repo_creation and cov_init) to set cov_init_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = getProjectsToRecalculate()\n",
    "\n",
    "i=1\n",
    "j=0\n",
    "for repo in repos: \n",
    "    project = repo[0]\n",
    "    repo_creation = repo[1]\n",
    "    print('Processing Dates: {}\\t\\t {}\\{}  -  {}'.format(project,i,len(repos),datetime.now().strftime(\"%d/%m/%y %H:%M:%S\")))\n",
    "    i+=1\n",
    "    \n",
    "    cov_init = getFirstCov(project)[0]\n",
    "    build_init = getFirstBuild(project)[0]\n",
    "    \n",
    "    if cov_init is not None and build_init is not None and cov_init < build_init:\n",
    "        cov_init = build_init\n",
    "    \n",
    "    print(cov_init)\n",
    "    \n",
    "    if cov_init is not None:\n",
    "        days = abs(cov_init.replace(tzinfo=None) - repo_creation.replace(tzinfo=None)).days\n",
    "        setCovInit(project,cov_init,days)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Redifining analysis_point and analysis_point_days for projects using CI Service\n",
    "\n",
    "- We ran the SQL:\n",
    "   - update projects set analysis_point_days = cov_init_days, analysis_point = cov_init where ci_service like 'Travis CI';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3. Get the new median days for CI projects (having cov_init not null) and set it on NO CI projects\n",
    "\n",
    "- Median of analysis point (Age on CI adoption)\n",
    "   - In terms of coverage and build practices\n",
    "- Process the median for CI projects (those having builds and coverages)\n",
    "- Set NON-CI projects with the median, all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianAge = getMedianCIAdoption()[0][0]\n",
    "print('Age median for CI adoption: {} days.'.format(medianAge))\n",
    "\n",
    "print('Setting this median as analysis_point for all NON-CI projects.')\n",
    "setNonCIProjectAnalysis_Point_Days(medianAge)\n",
    "print('Done.')\n",
    "\n",
    "repos = getNonCIProjects()\n",
    "i=0\n",
    "for repo in repos:  \n",
    "    project = repo[0]\n",
    "    created = repo[1]\n",
    "\n",
    "    if created is not None:\n",
    "        analysis_point = created + relativedelta(days=medianAge)\n",
    "\n",
    "        i += 1\n",
    "        print('{}/{} - {} Project {} - Created: {} - Days: {} - Analysis: {}'.format(i,len(repos),datetime.now().strftime(\"%H:%M:%S\"),project,created,medianAge,analysis_point))\n",
    "\n",
    "        setProjectAnalysis_Point(project,analysis_point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4. Setting Analysis_init and Analysis_finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = getProjectsMined()\n",
    "i=0\n",
    "\n",
    "for repo in repos:    \n",
    "    project = repo[0]\n",
    "    first_commit = repo[1]\n",
    "    \n",
    "    #Calculate init of the moth and finish of the last month\n",
    "    #Adjust the finish date to the first hour of the subsequent month\n",
    "    analysisInit = analysisFinish = datetime(first_commit.year, first_commit.month, 1, 0,0,0,tzinfo=first_commit.tzinfo)\n",
    "    analysisFinish = analysisFinish + relativedelta(months=+13)\n",
    "\n",
    "    \n",
    "    setAnalysis_init_finish(project,analysisInit,analysisFinish)\n",
    "        \n",
    "    \n",
    "    i += 1\n",
    "    print('{}/{} - Project {} - Init: {} - Finish: {}'.format(i,len(repos),project,analysisInit,analysisFinish))\n",
    "    #time.sleep(.02)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5. (Re)Process metrics quantities in analysis period:\n",
    "- Notebook 3_1:\n",
    "    - analysis_releases\n",
    "    - analysis_issues\n",
    "    - analysis_prs\n",
    "- Notebook 5_1:\n",
    "    - Mine Communication of pull requests in selected releases\n",
    "- Notebook 6:\n",
    "    - Consolidate pullrequests data via Github API\n",
    "- Notebook 7:\n",
    "    - qty_bugs_period\n",
    "    - qty_bugs\n",
    "    - Merge_conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for CI classification\n",
    "* Build Health (Median)\n",
    "    * Rate of builds passed.\n",
    "* Builds activity (Median)\n",
    "    * Frequency of days having builds in a given period of time (e.g. 10/30 days having builds in a month).\n",
    "* Time to Fix broken builds (Median)\n",
    "    * Time since a build fail status until the next success.\n",
    "* Test Coverage (Median)\n",
    "    * Percent of test coverage in a build\n",
    "\n",
    "### Process\n",
    "- Get analysis period (projects.analysis_init - projects.analysis_finish) for each project:\n",
    "    - Calculate Build Health, Build activity (integration frequency), Time to Fix broken builds, and Test Coverage;\n",
    "    - Get projects having values for coverage and build greater than 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate and record metric fields on table Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T19:00:38.921239Z",
     "start_time": "2021-11-09T18:59:01.329072Z"
    }
   },
   "outputs": [],
   "source": [
    "repos = getProjects()\n",
    "\n",
    "for repo in repos:    \n",
    "    project = repo[0]\n",
    "    analysisInit = repo[1]\n",
    "    analysisFinish = repo[2]\n",
    "    print('Processing CI Metrics. Project:\\t {}\\t {}  -  {}'.format(project,analysisInit,analysisFinish))\n",
    "    \n",
    "    buildHealth = calcBuildHealth(project,analysisInit,analysisFinish)\n",
    "    timeToFix = calcTimeToFix(project,analysisInit,analysisFinish)\n",
    "    builds_activity = calcActivity(project,analysisInit,analysisFinish)\n",
    "    coverage = calcCoverage(project,analysisInit,analysisFinish)\n",
    "    \n",
    "    updateProjectMetrics(project,buildHealth, timeToFix, builds_activity,coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T01:44:08.518547Z",
     "start_time": "2021-11-09T01:44:08.504971Z"
    }
   },
   "source": [
    "#### Flag CI Projects\n",
    "- Projects having:\n",
    "    - coverage > 0;\n",
    "    - Build (activity, health, ttf) > 0;\n",
    "    - prs_selected and issues_selected\n",
    "    - Travis CI project\n",
    "    \n",
    "#### Select CI Projects\n",
    "- Projects having:\n",
    "    - CI flag true (previous bullet);\n",
    "    - Bugs in analysis period;\n",
    "    \n",
    "#### Draw the same quantity of projects through NO CI instances\n",
    "- Projects having:\n",
    "    - No CI server\n",
    "    - prs_selected and issues_selected\n",
    "    - Bugs in analysis period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T19:10:26.659729Z",
     "start_time": "2022-02-08T19:10:25.573938Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "updateCIProjects()\n",
    "\n",
    "qty_projects = getQtyProjects()\n",
    "\n",
    "# Which of these groups is the lower?\n",
    "# Select all projects from this lower group\n",
    "# Then, draw the same quantity from the other.\n",
    "if qty_projects[0][1] < qty_projects[1][1]:\n",
    "    setSelectedAllProjects(qty_projects[0][0])\n",
    "    drawProjects(qty_projects[1][0],qty_projects[0][1])\n",
    "else:\n",
    "    setSelectedAllProjects(qty_projects[1][0])\n",
    "    drawProjects(qty_projects[0][0],qty_projects[1][1])\n",
    "    \n",
    "#drawNOCIProjects(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T19:04:39.056647Z",
     "start_time": "2022-02-08T19:04:39.048167Z"
    }
   },
   "outputs": [],
   "source": [
    "def drawProjects(ci,qty):\n",
    "    projects = getGroupProjects(ci)\n",
    "    projects = list(map(lambda x: x[0], projects))\n",
    "    i=0\n",
    "    \n",
    "    while i < qty:\n",
    "        random.shuffle(projects)\n",
    "        id = random.randint(0, len(projects)-1)\n",
    "        proj = projects.pop(id)\n",
    "        \n",
    "        i +=1\n",
    "        \n",
    "        print('PROJECT: {}'.format(proj))\n",
    "        try:\n",
    "            query = \"\"\"UPDATE  projects\n",
    "                set rq1_included = true\n",
    "                WHERE repo_name like %s\"\"\"\n",
    "\n",
    "            connection = connectDB()\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(query,[proj])\n",
    "            connection.commit()\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "        except psycopg2.IntegrityError as e:\n",
    "            print (\"==============================================================\")\n",
    "            print (\"Error while updating into PostgreSQL. drawProjects >>> Exception: {}\".format(e)) \n",
    "            connection.close()\n",
    "        except Exception as e:\n",
    "            print (\"==============================================================\")\n",
    "            print (\"Error while processing drawProjects >>> Exception: {}\".format(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T19:09:09.495453Z",
     "start_time": "2022-02-08T19:09:09.487093Z"
    }
   },
   "outputs": [],
   "source": [
    "def getGroupProjects(ci):\n",
    "    query = \"\"\"SELECT repo_name From projects \n",
    "                WHERE analysis_issues > 0 AND analysis_prs > 0 AND commits_mined is true \n",
    "                AND analysis_releases > 0 AND qty_bugs > 0\"\"\"\n",
    "    \n",
    "    if ci:\n",
    "        query += \"\"\" AND builds_activity > 0 AND coverage > 0 AND ci_service is not null;\"\"\"\n",
    "    else:\n",
    "        query += \"\"\" AND ci_service is NULL;\"\"\"\n",
    "            \n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T19:10:15.504374Z",
     "start_time": "2022-02-08T19:10:15.497595Z"
    }
   },
   "outputs": [],
   "source": [
    "def setSelectedAllProjects(ci):\n",
    "    try:\n",
    "        query = \"\"\"UPDATE  projects\n",
    "            set rq1_included = true\n",
    "            WHERE analysis_issues > 0 AND analysis_prs > 0 AND commits_mined is true \n",
    "                    AND analysis_releases > 0 AND qty_bugs > 0\"\"\"\n",
    "        \n",
    "        if ci:\n",
    "            query += \"\"\" AND builds_activity > 0 AND coverage > 0 AND ci_service is not null;\"\"\"\n",
    "        else:\n",
    "            query += \"\"\" AND ci_service is null;\"\"\"\n",
    "            \n",
    "\n",
    "        connection = connectDB()\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except psycopg2.IntegrityError as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while updating into PostgreSQL. setSelectedAllProjects >>> Exception: {}\".format(e)) \n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while processing setSelectedAllProjects >>> Exception: {}\".format(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T13:43:54.355103Z",
     "start_time": "2022-02-08T13:43:54.349016Z"
    }
   },
   "outputs": [],
   "source": [
    "def getQtyProjects():\n",
    "    query = \"\"\"select ci,count(repo_name) from projects WHERE \n",
    "                    analysis_issues > 0 AND analysis_prs > 0 AND commits_mined is true AND analysis_releases > 0 AND qty_bugs > 0 AND \n",
    "                    ((builds_activity > 0 AND coverage > 0 AND ci_service is not null) \n",
    "                    OR ci_service is null)\n",
    "                group by ci;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T13:24:48.225430Z",
     "start_time": "2022-02-08T13:24:48.220509Z"
    }
   },
   "outputs": [],
   "source": [
    "def updateCIProjects():\n",
    "    try:\n",
    "        query = \"\"\"UPDATE  projects \n",
    "            set ci = true\n",
    "            WHERE repo_name IN\n",
    "                (select repo_name from projects WHERE \n",
    "                    (commits_mined IS TRUE and analysis_releases > 0 and analysis_issues > 0 and analysis_prs > 0 \n",
    "                    and qty_bugs > 0\n",
    "                    and analysis_point_days is not null)\n",
    "                AND CI_SERVICE iLIKE 'TRAVIS CI'\n",
    "                AND coverage > 0 AND builds_activity > 0);                \n",
    "            \"\"\"\n",
    "\n",
    "        connection = connectDB()\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except psycopg2.IntegrityError as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while updating into PostgreSQL. updateCIProjects >>> Exception: {}\".format(e)) \n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while processing updateCIProjects >>> Exception: {}\".format(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:45.007408Z",
     "start_time": "2022-02-07T20:06:44.988774Z"
    }
   },
   "outputs": [],
   "source": [
    "def drawNOCIProjects(qty):\n",
    "    projects = getNOCIProjects()\n",
    "    projects = list(map(lambda x: x[0], projects))\n",
    "    i=0\n",
    "    \n",
    "    while i < qty:\n",
    "        random.shuffle(projects)\n",
    "        id = random.randint(0, len(projects)-1)\n",
    "        proj = projects.pop(id)\n",
    "        \n",
    "        i +=1\n",
    "        \n",
    "        print('PROJECT: {}'.format(proj))\n",
    "        try:\n",
    "            query = \"\"\"UPDATE  projects\n",
    "                set rq1 = true\n",
    "                WHERE repo_name like %s\"\"\"\n",
    "\n",
    "            connection = connectDB()\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(query,[proj])\n",
    "            connection.commit()\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "        except psycopg2.IntegrityError as e:\n",
    "            print (\"==============================================================\")\n",
    "            print (\"Error while updating into PostgreSQL. drawNOCIProjects >>> Exception: {}\".format(e)) \n",
    "            connection.close()\n",
    "        except Exception as e:\n",
    "            print (\"==============================================================\")\n",
    "            print (\"Error while processing drawNOCIProjects >>> Exception: {}\".format(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T13:18:19.982530Z",
     "start_time": "2021-11-09T13:18:19.957695Z"
    }
   },
   "outputs": [],
   "source": [
    "#calcActivity('3b1b/manim','2019-10-01 00:00:00-03:00','2020-10-01 00:00:00-03:00')\n",
    "#r=getBuildDays('3b1b/manim','2019-10-01 00:00:00-03','2020-10-01 00:00:00-03')\n",
    "#len(r)\n",
    "\n",
    "#r=getCoverage('ruslanskorb/RSKImageCropper','2015-03-01 00:00:00-03:00','2016-03-01 00:00:00-03:00')\n",
    "#type(r)\n",
    "#if r.empty:\n",
    "#    print('eita')\n",
    "#calcCoverage('3b1b/manim','2019-10-01 00:00:00-03','2020-10-01 00:00:00-03')\n",
    "#r\n",
    "#print(r['coverage'].median())\n",
    "#r = removeOutliers(r)\n",
    "#print(r['coverage'].median())\n",
    "#failBuilds = getFailBuilds('3b1b/manim')\n",
    "#nextDate = getNextSuccess('3b1b/manim',failBuilds[0][1])\n",
    "#nextDate[0][1]\n",
    "#diff = (nextDate[0][1] - failBuilds[0][1]).total_seconds()\n",
    "#diff\n",
    "#fillTimeToNextSuccess('3b1b/manim')\n",
    "\n",
    "#calcTimeToFix('3b1b/manim','2019-10-01 00:00:00-03','2020-10-01 00:00:00-03')\n",
    "#ttfs = getTTFs('3b1b/manim','2019-10-01 00:00:00-03','2020-10-01 00:00:00-03')\n",
    "#ttfs['time_to_fix'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aux Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.603532Z",
     "start_time": "2022-02-07T20:06:35.626211Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "import requests \n",
    "import time\n",
    "import pytz    \n",
    "from datetime import datetime, timedelta, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dateutil.parser\n",
    "import random\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.609074Z",
     "start_time": "2022-02-07T20:06:36.605167Z"
    }
   },
   "outputs": [],
   "source": [
    "def connectDB():\n",
    "    f = open('/home/psql_pwd.txt', \"r\")\n",
    "    pwd = f.readline().replace('\\n','')\n",
    "    \n",
    "    return psycopg2.connect(user = \"ci_quality\",\n",
    "                              password = pwd,\n",
    "                              host = \"127.0.0.1\",\n",
    "                              port = \"5432\",\n",
    "                              database = \"Causal_CI_Quality_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectDBPandas():\n",
    "    f = open('/home/psql_pwd.txt', \"r\")\n",
    "    pwd = f.readline().replace('\\n','')\n",
    "    \n",
    "    #\"User ID=ci_quality;Password={};Host=localhost;Port=5432;Database=Causal_CI_Quality_v4;Pooling=true;Min Pool Size=0;Max Pool Size=100;Connection Lifetime=0;\".format(pwd)\n",
    "    DATABASE_URI = 'postgresql://ci_quality:{}@localhost:5432/Causal_CI_Quality_v4'.format(pwd)\n",
    "    #connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "    \n",
    "    return create_engine(DATABASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.618939Z",
     "start_time": "2022-02-07T20:06:36.611457Z"
    }
   },
   "outputs": [],
   "source": [
    "def getProjects():\n",
    "    #query = \"\"\"SELECT repo_name, min(init_period), max(end_period) From metrics_period \n",
    "    #    WHERE period ilike 'month' and repo_name IN \n",
    "    #        (SELECT repo_name From PROJECTS WHERE (prs_selected IS TRUE and issues_selected is true) AND CI_SERVICE iLIKE 'TRAVIS CI')\n",
    "    #    GROUP BY repo_name\n",
    "    #    order by repo_name --offset 400\"\"\"\n",
    "\n",
    "    query = \"\"\"SELECT repo_name, analysis_init, analysis_finish, analysis_point From PROJECTS \n",
    "    WHERE commits_mined IS TRUE and analysis_releases > 0 and analysis_issues > 0 and analysis_prs > 0 \n",
    "    and qty_bugs > 0\n",
    "    and analysis_point_days is not null\n",
    "    and CI_SERVICE ILIKE 'TRAVIS CI'\n",
    "    order by repo_name;\"\"\"\n",
    "    \n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProjectsToRecalculate():\n",
    "    query = \"\"\"SELECT repo_name, created From PROJECTS \n",
    "    WHERE CI_SERVICE ILIKE 'TRAVIS CI'\n",
    "    order by repo_name;\"\"\"\n",
    "    \n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.664943Z",
     "start_time": "2022-02-07T20:06:36.620643Z"
    }
   },
   "outputs": [],
   "source": [
    "def getNOCIProjects():\n",
    "    query = \"\"\"SELECT repo_name From PROJECTS \n",
    "    WHERE commits_mined2 IS TRUE and analysis_releases > 1 and analysis_issues > 0 and analysis_prs > 0 \n",
    "    and qty_bugs_period > 0\n",
    "    and CI_SERVICE is NULL\n",
    "    order by repo_name;\"\"\"\n",
    "    \n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.689691Z",
     "start_time": "2022-02-07T20:06:36.666821Z"
    }
   },
   "outputs": [],
   "source": [
    "def getAllProjects():\n",
    "    query = \"\"\"SELECT repo_name From PROJECTS \n",
    "    WHERE commits_mined2 IS TRUE and analysis_releases > 1 and analysis_issues > 0 and analysis_prs > 0 \n",
    "    and qty_bugs_period > 0\n",
    "    order by repo_name;\"\"\"\n",
    "    \n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.715036Z",
     "start_time": "2022-02-07T20:06:36.691556Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcBuildHealth(project,init, finish):\n",
    "    builds = getBuildResults(project, init, finish)\n",
    "    buildHealth = computeBuildHealth(builds)\n",
    "\n",
    "    print('\\t\\t\\t Build Health: {} - Total builds: {}'.format(buildHealth,len(builds)))\n",
    "    return buildHealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.739606Z",
     "start_time": "2022-02-07T20:06:36.717261Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcTimeToFix(project,init, finish):\n",
    "    fillTimeToNextSuccess(project)\n",
    "    \n",
    "    ttfs = getTTFs(project, init, finish)\n",
    "    if ttfs.empty:\n",
    "        ttf = 0\n",
    "    else:\n",
    "        ttf = ttfs['time_to_fix'].median()\n",
    "        \n",
    "    print('\\t\\t\\t Time To Fix: {} - Qty data ttf: {}'.format(ttf,ttfs['time_to_fix'].count()))\n",
    "    return ttf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.767616Z",
     "start_time": "2022-02-07T20:06:36.742217Z"
    }
   },
   "outputs": [],
   "source": [
    "def fillTimeToNextSuccess(project):\n",
    "    #Get all failed builds\n",
    "    failBuilds = getFailBuilds(project)\n",
    "    #For each build, get the next success and update it.\n",
    "    for b in failBuilds:\n",
    "        fail = b[1]\n",
    "        nextDate = getNextSuccess(project,fail)#created\n",
    "        if nextDate is not None and len(nextDate) > 0:\n",
    "            success = nextDate[0][1]\n",
    "        \n",
    "            diff = (success - fail).total_seconds()\n",
    "        \n",
    "            updateBuildTTF(project,b[0],diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.814097Z",
     "start_time": "2022-02-07T20:06:36.773258Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcActivity(project,init, finish):\n",
    "    #init = dateutil.parser.parse(init)\n",
    "    #finish = dateutil.parser.parse(finish)\n",
    "    days = (finish - init).days\n",
    "    \n",
    "    build_days = getBuildDays(project, init, finish)\n",
    "    build_activity = len(build_days)/days\n",
    "\n",
    "    print('\\t\\t\\t Build Activity: {} - Total Activity Days: {} - Total Days: {}'.format(build_activity,len(build_days),days))\n",
    "    return build_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.838208Z",
     "start_time": "2022-02-07T20:06:36.816588Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcCoverage(project,init, finish):\n",
    "    covs = getCoverage(project, init, finish)\n",
    "    if covs.empty:\n",
    "        coverage = 0\n",
    "    else:\n",
    "        if checkValues(covs['coverage']):\n",
    "            coverage = covs['coverage'].median()\n",
    "        else:\n",
    "           # coverage = removeOutliers(covs)\n",
    "            coverage = covs['coverage'].median()\n",
    "        \n",
    "        #coverage = covs['coverage'].median()\n",
    "        \n",
    "    print('\\t\\t\\t Coverage: {} - Qty data cov: {}'.format(coverage,covs['coverage'].count()))\n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.863155Z",
     "start_time": "2022-02-07T20:06:36.839877Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBuildResults(repo_name,initDate, finishDate):    \n",
    "    query = \"\"\"SELECT result FROM builds_mined WHERE \n",
    "            repo_name = %s AND ((STARTED_at BETWEEN %s AND %s) OR (finishED_at BETWEEN %s AND %s))\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name,initDate, finishDate,initDate, finishDate])\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.887641Z",
     "start_time": "2022-02-07T20:06:36.865050Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFailBuilds(repo_name):    \n",
    "    query = \"\"\"select build_number, started_at, result from builds_mined \n",
    "        WHERE repo_name = %s AND result is False AND started_at is not NULL AND time_to_fix is NULL\n",
    "        order by started_at\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name])\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.936490Z",
     "start_time": "2022-02-07T20:06:36.889323Z"
    }
   },
   "outputs": [],
   "source": [
    "def getNextSuccess(repo_name,date):    \n",
    "    query = \"\"\"select build_number, started_at, result from builds_mined \n",
    "        WHERE repo_name = %s AND result is True  AND started_at > %s\n",
    "        order by started_at limit 1;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name,date])\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.961233Z",
     "start_time": "2022-02-07T20:06:36.941749Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBuildDays(project, init, finish):\n",
    "    query = \"\"\"select distinct date(started_at) from builds_mined\n",
    "                WHERE repo_name = %s AND (STARTED_at BETWEEN %s AND %s);\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [project,init, finish])\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:36.989961Z",
     "start_time": "2022-02-07T20:06:36.963995Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCoverage(project_name,init,finish):\n",
    "    connection = connectDBPandas()\n",
    "    query = 'select coverage from coverage where (created BETWEEN %s AND %s) AND repo_name like %s;'\n",
    "\n",
    "    df = pd.read_sql_query(query,con=connection,params=[init,finish,project_name])\n",
    "    #connection.close()\n",
    "    \n",
    "    #Check if column contains all values 0. In this case we do not filter outliers.\n",
    "    #if checkValues(df['coverage']):\n",
    "    return df\n",
    "    #else:\n",
    "    #    return removeOutliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.018367Z",
     "start_time": "2022-02-07T20:06:36.993214Z"
    }
   },
   "outputs": [],
   "source": [
    "def getTTFs(project_name,init,finish):\n",
    "    connection = connectDBPandas()\n",
    "    query = 'select time_to_fix from builds_mined where time_to_fix is not Null AND repo_name like %s AND (started_at BETWEEN %s AND %s);'\n",
    "\n",
    "    df = pd.read_sql_query(query,con=connection,params=[project_name,init,finish])\n",
    "    #connection.close()\n",
    "    #Check if column contains all values 0. In this case we do not filter outliers.\n",
    "    #if checkValues(df['time_to_fix']):\n",
    "    #    return df\n",
    "    #else:\n",
    "    #    return removeOutliers(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.064116Z",
     "start_time": "2022-02-07T20:06:37.020274Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeBuildHealth(builds):\n",
    "    results = list(map(lambda x: x[0], builds))\n",
    "    success = list(filter(lambda x: x == True, results))\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        return len(success)/len(results)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.088673Z",
     "start_time": "2022-02-07T20:06:37.066099Z"
    }
   },
   "outputs": [],
   "source": [
    "def updateProjectMetrics(repo_name,build_health, timeToFix, builds_actvity,coverage):\n",
    "    try:\n",
    "        query = \"\"\"UPDATE  projects \n",
    "            set build_health = %s,\n",
    "                time_to_fix_broken_builds = %s,\n",
    "                builds_activity = %s,\n",
    "                coverage = %s\n",
    "            WHERE repo_name like %s\"\"\"\n",
    "\n",
    "        connection = connectDB()\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query, [build_health, timeToFix, builds_actvity,coverage,repo_name])\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except psycopg2.IntegrityError as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while updating into PostgreSQL. updateProjectMetrics >>> Exception: {}\".format(e)) \n",
    "        print('Project: {}'.format(repo_name))\n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while processing updateProjectMetrics >>> Exception: {}\".format(e)) \n",
    "        print('Project: {}'.format(repo_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.113814Z",
     "start_time": "2022-02-07T20:06:37.090212Z"
    }
   },
   "outputs": [],
   "source": [
    "def updateBuildTTF(project, build_number, timeToFix):\n",
    "    try:\n",
    "        query = \"\"\"UPDATE  builds_mined \n",
    "            set time_to_fix = %s\n",
    "            WHERE repo_name like %s AND build_number = %s\"\"\"\n",
    "\n",
    "        connection = connectDB()\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query, [timeToFix, project, build_number])\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except psycopg2.IntegrityError as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while updating into PostgreSQL. updateBuildTTF >>> Exception: {}\".format(e)) \n",
    "        print('Project: {}    PR - {} '.format(repo_name, pr_number))\n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while processing updateBuildTTF >>> Exception: {}\".format(e)) \n",
    "        print('Project: {}    PR - {}  '.format(repo_name, pr_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.160237Z",
     "start_time": "2022-02-07T20:06:37.116602Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://www.kite.com/python/answers/how-to-remove-outliers-from-a-pandas-dataframe-in-python\n",
    "def removeOutliers(df):\n",
    "    z_scores = stats.zscore(df)\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "    df_filtered = df[filtered_entries]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.187230Z",
     "start_time": "2022-02-07T20:06:37.162084Z"
    }
   },
   "outputs": [],
   "source": [
    "def checkValues(df):\n",
    "    if (df == 0).all():\n",
    "        return True\n",
    "    else:\n",
    "        i=v=0\n",
    "        v = df[0]\n",
    "        for a in df:\n",
    "            if a != v:\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.211840Z",
     "start_time": "2022-02-07T20:06:37.189238Z"
    }
   },
   "outputs": [],
   "source": [
    "def countPRsProject(project, mergeConflict=None):\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    if mergeConflict is None or mergeConflict is False:\n",
    "        query = \"\"\"SELECT count(id) from pullrequests WHERE project_name like %s\"\"\"\n",
    "    else:\n",
    "        query = \"\"\"SELECT count(id) from pullrequests WHERE project_name like %s and mergeconflict is True\"\"\"\n",
    "\n",
    "    cursor.execute(query, [project])\n",
    "    row = cursor.fetchone()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    if row is not None:\n",
    "        return row[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.257636Z",
     "start_time": "2022-02-07T20:06:37.216230Z"
    }
   },
   "outputs": [],
   "source": [
    "def countIssuesProject(project, bug=None):\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    if bug is None or bug is False:\n",
    "        query = \"\"\"SELECT count(id) from issue WHERE repo_name like %s\"\"\"\n",
    "    elif bug is True:\n",
    "        query = \"\"\"SELECT count(id) from issue WHERE repo_name like %s and isbug is True\"\"\"\n",
    "\n",
    "    cursor.execute(query, [project])\n",
    "    row = cursor.fetchone()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    if row is not None:\n",
    "        return row[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.283025Z",
     "start_time": "2022-02-07T20:06:37.259160Z"
    }
   },
   "outputs": [],
   "source": [
    "def updateProjectQty(repo_name,qtd_issues, qtd_pull_requests, qtd_bugs,qtd_merge_conflics):\n",
    "    try:\n",
    "        query = \"\"\"UPDATE  projects \n",
    "            set qtd_issues = %s,\n",
    "                qtd_pull_requests = %s,\n",
    "                qtd_bugs = %s,\n",
    "                qtd_merge_conflics = %s\n",
    "            WHERE repo_name like %s\"\"\"\n",
    "\n",
    "        connection = connectDB()\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query, [qtd_issues, qtd_pull_requests, qtd_bugs,qtd_merge_conflics,repo_name])\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except psycopg2.IntegrityError as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while updating into PostgreSQL. updateProjectQty >>> Exception: {}\".format(e)) \n",
    "        print('Project: {}'.format(repo_name))\n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while processing updateProjectQty >>> Exception: {}\".format(e)) \n",
    "        print('Project: {}'.format(repo_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstCov(repo_name):    \n",
    "    query = \"\"\"SELECT min(created) FROM coverage WHERE \n",
    "            repo_name = %s;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name])\n",
    "    rows = cursor.fetchone()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstBuild(repo_name):    \n",
    "    query = \"\"\"SELECT min(started_at) FROM builds_mined WHERE \n",
    "            repo_name = %s;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name])\n",
    "    rows = cursor.fetchone()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCovInit(repo_name,cov_init,cov_init_days):\n",
    "    try:\n",
    "        query = \"\"\"UPDATE  projects\n",
    "            set cov_init = %s,\n",
    "                cov_init_days = %s\n",
    "            WHERE repo_name like %s;\"\"\"\n",
    "            \n",
    "\n",
    "        connection = connectDB()\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query,[cov_init,cov_init_days,repo_name])\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except psycopg2.IntegrityError as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while updating into PostgreSQL. setCovInit >>> Exception: {}\".format(e)) \n",
    "        connection.close()\n",
    "    except Exception as e:\n",
    "        print (\"==============================================================\")\n",
    "        print (\"Error while processing setCovInit >>> Exception: {}\".format(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNonCIProjects():\n",
    "    query = \"\"\"select repo_name, created from projects\n",
    "            where qtd_stars >= 100 and forked is false and size  > 10000\n",
    "            and ci_service is null \n",
    "            order by repo_name;\"\"\"\n",
    "    \n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setProjectAnalysis_Point(repo_name,date):\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    query = \"\"\"UPDATE  projects \n",
    "    set analysis_point = %s\n",
    "    WHERE repo_name like %s;\"\"\"\n",
    "\n",
    "    cursor.execute(query, [date,repo_name])\n",
    "        \n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProjectsMined():\n",
    "    query = \"\"\"SELECT repo_name, analysis_point From PROJECTS \n",
    "    where  qtd_stars >= 100 and forked is false and size  > 10000\n",
    "            and ((ci_service is null or ci_service like 'Travis CI') and analysis_point is not null)\n",
    "            order by repo_name desc;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAnalysis_init_finish(repo_name,date_init,date_finish):\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    query = \"\"\"UPDATE  projects \n",
    "    set analysis_init = %s,\n",
    "    analysis_finish = %s\n",
    "    WHERE repo_name like %s;\"\"\"\n",
    "\n",
    "    cursor.execute(query, [date_init,date_finish,repo_name])\n",
    "        \n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMedianCIAdoption():\n",
    "    query = \"\"\"select  PERCENTILE_CONT(0.5) WITHIN GROUP(ORDER BY ci_service_init_days) from projects\n",
    "            where analysis_issues > 0 and analysis_prs > 0 and commits_mined is true AND analysis_releases > 0\n",
    "                AND qty_bugs > 0 \n",
    "                AND analysis_point_days is not null\n",
    "                AND builds_activity > 0\n",
    "                AND coverage > 0\n",
    "                and ci_service ilike 'Travis CI';\"\"\"\n",
    "    #AND builds_activity > 0\n",
    "    #AND coverage > 0\n",
    "    \n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setNonCIProjectAnalysis_Point_Days(days):\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    query = \"\"\"UPDATE  projects \n",
    "    set analysis_point_days = %s\n",
    "    WHERE qtd_stars >= 100 \n",
    "        and forked is false \n",
    "        and size  > 10000\n",
    "        and ci_service is null;\"\"\"\n",
    "\n",
    "    cursor.execute(query, [days])\n",
    "        \n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.308393Z",
     "start_time": "2022-02-07T20:06:37.284731Z"
    }
   },
   "outputs": [],
   "source": [
    "def getCIProjectsMetrics(ci=None):\n",
    "    \n",
    "    if ci is None:\n",
    "        query = \"\"\"select qtd_stars, qtd_issues, qtd_issues_in_period,qtd_pull_requests,qtd_pull_request_in_period,qtd_bugs,qtd_merge_conflicts,COVERAGE,BUILDS_ACTIVITY, TIME_TO_FIX_BROKEN_BUILDS, BUILD_HEALTH\n",
    "                from projects where rq1 is true;\"\"\"\n",
    "    elif ci is True:\n",
    "        query = \"\"\"select qtd_stars, qtd_issues, qtd_issues_in_period,qtd_pull_requests,qtd_pull_request_in_period,qtd_bugs,qtd_merge_conflicts,COVERAGE,BUILDS_ACTIVITY, TIME_TO_FIX_BROKEN_BUILDS, BUILD_HEALTH\n",
    "                from projects where rq1 is true AND ci is True;\"\"\"\n",
    "    else:\n",
    "        query = \"\"\"select qtd_stars, qtd_issues, qtd_issues_in_period,qtd_pull_requests,qtd_pull_request_in_period,qtd_bugs,qtd_merge_conflicts,COVERAGE,BUILDS_ACTIVITY, TIME_TO_FIX_BROKEN_BUILDS, BUILD_HEALTH\n",
    "                from projects where rq1 is true AND ci is false;\"\"\"\n",
    "    \n",
    "    connection = connectDB()\n",
    "    df = pd.read_sql_query(query,con=connection)\n",
    "    connection.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBuildDates(repo_name):    \n",
    "    query = \"\"\"SELECT min(STARTED_at),max(STARTED_at) FROM builds_mined WHERE \n",
    "            repo_name = %s;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name])\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCovsDates(repo_name):    \n",
    "    query = \"\"\"SELECT min(created),max(created) FROM coverage WHERE \n",
    "            repo_name = %s;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name])\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBugsDates(repo_name):    \n",
    "    query = \"\"\"SELECT min(created_at),max(created_at) FROM issue \n",
    "            WHERE repo_name = %s AND isbug is true;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name])\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReleasesDates(repo_name):    \n",
    "    query = \"\"\"SELECT min(created_at),max(created_at) FROM RELEASES \n",
    "            WHERE repo_name = %s AND isbug is true;\"\"\"\n",
    "\n",
    "    connection = connectDB()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    cursor.execute(query, [repo_name])\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.315360Z",
     "start_time": "2022-02-07T20:06:37.309930Z"
    }
   },
   "outputs": [],
   "source": [
    "'''projects = getAllProjects()\n",
    "\n",
    "i=1\n",
    "for proj in projects:\n",
    "    project = proj[0]\n",
    "    \n",
    "    print('Updating project {}/{}  --  {}'.format(i,len(projects),project))\n",
    "    total_prs = countPRsProject(project)\n",
    "    total_merge_conflicts = countPRsProject(project,True)\n",
    "    total_issues = countIssuesProject(project)\n",
    "    total_bugs = countIssuesProject(project,True)\n",
    "    \n",
    "    updateProjectQty(project,total_issues, total_prs, total_bugs,total_merge_conflicts)\n",
    "    i+=1\n",
    "    \n",
    "    dates_covs = getCovsDates(project)\n",
    "    dates_bugs = getBugsDates(project)\n",
    "    dates_releases = getReleasesDates(project)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T20:06:37.319517Z",
     "start_time": "2022-02-07T20:06:37.317272Z"
    }
   },
   "outputs": [],
   "source": [
    "#projects = getCIProjectsMetrics(ci=None)\n",
    "#projects.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
